{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing public libraries\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import epynet\n",
    "import yaml\n",
    "import torch\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import from_networkx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing custom libraries\n",
    "from utils.epanet_loader import get_nx_graph\n",
    "from utils.visualisation import visualise\n",
    "from utils.epanet_simulator import epanetSimulator\n",
    "from utils.data_loader import battledimLoader, dataCleaner, dataGenerator, embedSignalOnGraph, rescaleSignal, predictionTaskDataSplitter\n",
    "from utils.early_stopping import EarlyStopping\n",
    "from modules.torch_gnn import ChebNet\n",
    "import utils.user_interface as ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import ChebConv\n",
    "\n",
    "from utils.metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 3070 Ti Laptop GPU\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: \t 'import_model.py' \n",
      "Using device: \t cuda\n",
      "\n",
      "Configurations for session: \n",
      "----------------------\n",
      "WDN: l-town\n",
      "GNN: chebnet\n",
      "Weights: pipe_length\n",
      "Visualise: yes\n",
      "Visualise What: sensor_location\n",
      "Scaling: minmax\n",
      "Tag: tag\n",
      "Epochs: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"\\nRunning: \\t 'import_model.py' \")\n",
    "print(\"Using device: \\t {}\".format(device))\n",
    "\n",
    "# Hardcoded configurations\n",
    "wdn = 'l-town'  # Choice of water-distribution network\n",
    "gnn = 'chebnet'  # Choice of GNN model\n",
    "# weights = 'unweighted'  # Edge weights type\n",
    "weights = 'pipe_length'  # Edge weights type\n",
    "visualise = 'yes'  # Visualise the graph\n",
    "visualiseWhat = 'sensor_location'  # What to visualise\n",
    "scaling = 'minmax'  # Rescaling method\n",
    "tag = 'tag'  # Descriptive tag\n",
    "epochs = 100  # Number of training epochs\n",
    "\n",
    "self_loop = True \n",
    "\n",
    "print(\"\\nConfigurations for session: \\n\" + 22*\"-\")\n",
    "print(\"WDN: {}\\nGNN: {}\\nWeights: {}\\nVisualise: {}\\nVisualise What: {}\\nScaling: {}\\nTag: {}\\nEpochs: {}\\n\".format(\n",
    "    wdn, gnn, weights, visualise, visualiseWhat, scaling, tag, epochs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment paths...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the filepaths for the execution\n",
    "print('Setting environment paths...\\n')\n",
    "\n",
    "path_to_data   = './data/' + wdn + '-data/'       # Datasets are stored here\n",
    "path_to_wdn    = './data/' + wdn.upper() + '.inp' # EPANET input file\n",
    "path_to_logs   = './studies/logs/'                     # Log directory\n",
    "path_to_figs   = './studies/figs/'                     # Figure directory\n",
    "path_to_models = './studies/models/'                   # Saved models directory               \n",
    "\n",
    "execution_no   = 1                                                                  # Initialise execution ID number\n",
    "execution_id   = wdn + '-' + gnn + '-' + weights + '-' + scaling + '-' + '{}'.format('self_loop-' if self_loop else '')# Initialise execution ID name\n",
    "logs           = [log for log in os.listdir(path_to_logs) if log.endswith('.csv')]  # Load all logs in directory to list\n",
    "\n",
    "while execution_id + str(execution_no) + '.csv' in logs:    # For every matching file name in the directory\n",
    "    execution_no += 1                                       # Increment the execution id number\n",
    "\n",
    "execution_id   = execution_id + str(execution_no)           # Update the execution ID\n",
    "model_path     = path_to_models + execution_id + '.pt'      # Generate complete model path w/ filename\n",
    "log_path       = path_to_logs   + execution_id + '.csv'     # Generate complete log path w/ filename\n",
    "\n",
    "# If we have already trained a similar model we may wish to load its weights\n",
    "# So, we must also generate a path to that model's state dictionary\n",
    "if execution_no > 1:\n",
    "    last_id         = wdn + '-' + gnn + '-' + tag + '-' # Initialise previous version execution ID name\n",
    "    last_id         = last_id + str(execution_no - 1)                  # Execution ID number is the current number - 1  \n",
    "    last_model_path = path_to_models + last_id + '.pt'                 # Generate complete path to the previously trained model\n",
    "    last_log_path   = path_to_logs   + last_id + '.csv'                # Generate complete path to the previous \n",
    "\n",
    "\n",
    "figsize     = (60,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dataset configuration...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Importing dataset configuration...\\n')\n",
    "\n",
    "# Open the dataset configuration file\n",
    "with open(path_to_data + 'dataset_configuration.yaml') as file:\n",
    "    \n",
    "    # Load the configuration to a dictionary\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader) \n",
    "\n",
    "# Generate a list of integers, indicating the number of the node\n",
    "# at which a  pressure sensor is present\n",
    "sensors = [int(string.replace(\"n\", \"\")) for string in config['pressure_sensors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running EPANET simulation to generate nominal pressure data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Running EPANET simulation to generate nominal pressure data...\\n')\n",
    "nominal_wdn_model = epanetSimulator(path_to_wdn, path_to_data)\n",
    "nominal_wdn_model.simulate()\n",
    "nominal_pressure = nominal_wdn_model.get_simulated_pressure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing EPANET file and converting to graph...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Importing EPANET file and converting to graph...\\n')\n",
    "\n",
    "# Import the .inp file using the EPYNET library\n",
    "wdn = epynet.Network(path_to_wdn)\n",
    "\n",
    "# Solve hydraulic model for a single timestep\n",
    "wdn.solve()\n",
    "\n",
    "# Convert the file using a custom function, based on:\n",
    "# https://github.com/BME-SmartLab/GraphConvWat \n",
    "G , pos , head = get_nx_graph(wdn, weight_mode=weights, get_head=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,scale,bias = dataCleaner(pressure_df    = nominal_pressure, \n",
    "                             observed_nodes = sensors,\n",
    "                             rescale        = scaling,\n",
    "                             mode           = 'sensor_mask',\n",
    "                             task           = 'reconstruction',)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_trn, x_val, y_trn, y_val = train_test_split(x, y, \n",
    "                                                test_size    = 0.2,\n",
    "                                                random_state = 1,\n",
    "                                                shuffle      = False)     # To maintain temporal consistency we don't shuffle the pressure data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>772</th>\n",
       "      <th>773</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.082881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.083183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>0.073622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>0.073450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>0.073279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>0.073107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>0.072934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1613 rows Ã— 782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1    2         3    4    5    6    7    8    9    ...  772  \\\n",
       "0     0.082881  0.0  0.0  0.183379  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1     0.083183  0.0  0.0  0.183678  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2     0.083487  0.0  0.0  0.183979  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "3     0.083791  0.0  0.0  0.184280  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "4     0.084095  0.0  0.0  0.184582  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "...        ...  ...  ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1608  0.073622  0.0  0.0  0.174194  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1609  0.073450  0.0  0.0  0.174021  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1610  0.073279  0.0  0.0  0.173849  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1611  0.073107  0.0  0.0  0.173675  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1612  0.072934  0.0  0.0  0.173502  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "      773  774  775  776  777  778  779  780  781  \n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "1608  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1609  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1610  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1611  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1612  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1613 rows x 782 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_trn[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(x_val[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor_node in sensors:\n",
    "    G.add_edge(u_of_edge=sensor_node,\n",
    "                v_of_edge=sensor_node,\n",
    "                weight=1.,name='SELF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up training session and creating model...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Setting up training session and creating model...\\n')\n",
    "\n",
    "# ----------------\n",
    "# Hyper-parameters\n",
    "# ----------------\n",
    "batch_size    = 40\n",
    "learning_rate = 3e-4\n",
    "decay         = 6e-6\n",
    "epochs        = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\30806\\anaconda3\\envs\\Msc\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate training and test set data generators, sequential mini-batches, randomly sampled\n",
    "trn_gnrtr = dataGenerator(G, x_trn, y_trn, batch_size, drop_last=False)\n",
    "val_gnrtr = dataGenerator(G, x_val, y_val, batch_size, drop_last=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a self loop to the sensor nodes\n",
    "if self_loop:\n",
    "    for sensor_node in sensors:\n",
    "        G.add_edge(u_of_edge=sensor_node,v_of_edge=sensor_node,weight=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Instantiate a Chebysev Network GNN model\n",
    "model     = ChebNet(name           = 'ChebNet',\n",
    "                    data_generator = trn_gnrtr,\n",
    "                    device         = device, \n",
    "                    in_channels    = np.shape(x_trn)[-1], \n",
    "                    out_channels   = np.shape(y_trn)[-1],\n",
    "                    data_scale     = scale, \n",
    "                    data_bias      = bias).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an optimizer\n",
    "optimizer = torch.optim.Adam([dict(params=model.conv1.parameters(), weight_decay=decay),\n",
    "                            dict(params=model.conv2.parameters(), weight_decay=decay),\n",
    "                            dict(params=model.conv3.parameters(), weight_decay=decay),\n",
    "                            dict(params=model.conv4.parameters(), weight_decay=0)],\n",
    "                            lr  = learning_rate,\n",
    "                            eps = 1e-7)\n",
    "\n",
    "# Configure an early stopping callback\n",
    "estop    = EarlyStopping(min_delta=.00001, patience=epochs)       # By setting patience as # of epochs we make sure early stopping is never initiated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting...\n",
      "\n",
      "epoch   trn_loss      val_loss    val_rel_err  val_rel_err_o val_rel_err_h run_time\n",
      "  1     0.034302      0.001995      0.036826      0.039356      0.036715    39.74  sec\n",
      "  2     0.000772      0.000252      0.010609      0.010424      0.010617    38.75  sec\n",
      "  3     0.000166      0.000081      0.007691      0.008044      0.007676    38.73  sec\n",
      "  4     0.000088      0.000081      0.007572      0.007515      0.007575    38.86  sec\n",
      "  5     0.000121      0.000114      0.009298      0.009833      0.009274    39.07  sec\n",
      "  6     0.000153      0.000205      0.012590      0.014501      0.012506    38.76  sec\n",
      "  7     0.000143      0.000063      0.006887      0.008427      0.006820    38.82  sec\n",
      "  8     0.000161      0.000078      0.007672      0.008123      0.007652    39.01  sec\n",
      "  9     0.000104      0.000071      0.007364      0.008291      0.007323    38.89  sec\n",
      " 10     0.000164      0.000122      0.009738      0.010328      0.009712    39.11  sec\n",
      " 11     0.000094      0.000058      0.006471      0.007313      0.006434    38.92  sec\n",
      " 12     0.000084      0.000060      0.006930      0.007873      0.006888    39.01  sec\n",
      " 13     0.000215      0.000068      0.007246      0.007554      0.007232    38.86  sec\n",
      " 14     0.000074      0.000215      0.013429      0.014610      0.013377    39.03  sec\n",
      " 15     0.000145      0.000098      0.009048      0.010330      0.008991    38.97  sec\n",
      " 16     0.000069      0.000051      0.006133      0.007044      0.006093    38.93  sec\n",
      " 17     0.000066      0.000109      0.009579      0.010206      0.009552    38.99  sec\n",
      " 18     0.000110      0.000069      0.007252      0.007994      0.007219    38.95  sec\n",
      " 19     0.000060      0.000055      0.006497      0.008079      0.006428    39.06  sec\n",
      "epoch   trn_loss      val_loss    val_rel_err  val_rel_err_o val_rel_err_h run_time\n",
      " 20     0.000090      0.000045      0.005796      0.006933      0.005745    38.99  sec\n",
      " 21     0.000083      0.000092      0.008516      0.008592      0.008513    39.26  sec\n",
      " 22     0.000132      0.000059      0.006659      0.007698      0.006613    39.15  sec\n",
      " 23     0.000070      0.000039      0.005271      0.005682      0.005253    39.13  sec\n",
      " 24     0.000075      0.000134      0.010547      0.010865      0.010533    38.90  sec\n",
      " 25     0.000118      0.000313      0.016153      0.018385      0.016055    39.03  sec\n",
      " 26     0.000123      0.000051      0.006081      0.007221      0.006031    39.00  sec\n",
      " 27     0.000066      0.000075      0.007649      0.008800      0.007598    39.59  sec\n",
      " 28     0.000079      0.000176      0.012464      0.014204      0.012388    39.52  sec\n",
      " 29     0.000150      0.000052      0.006117      0.007714      0.006046    39.06  sec\n",
      " 30     0.000054      0.000078      0.007836      0.008768      0.007795    39.04  sec\n",
      " 31     0.000094      0.000074      0.007584      0.008573      0.007541    39.17  sec\n",
      " 32     0.000066      0.000049      0.005939      0.006691      0.005905    39.07  sec\n",
      " 33     0.000073      0.000047      0.005923      0.006402      0.005902    39.10  sec\n",
      " 34     0.000087      0.000051      0.006132      0.006900      0.006098    39.38  sec\n",
      " 35     0.000063      0.000047      0.005968      0.006900      0.005927    39.27  sec\n",
      " 36     0.000062      0.000042      0.005803      0.006454      0.005774    39.02  sec\n",
      " 37     0.000085      0.000128      0.010361      0.011849      0.010295    39.03  sec\n",
      " 38     0.000102      0.000083      0.007654      0.008342      0.007624    39.06  sec\n",
      " 39     0.000072      0.000047      0.006008      0.005990      0.006009    39.12  sec\n",
      "epoch   trn_loss      val_loss    val_rel_err  val_rel_err_o val_rel_err_h run_time\n",
      " 40     0.000076      0.000074      0.007417      0.007479      0.007414    39.19  sec\n",
      " 41     0.000064      0.000064      0.007318      0.007359      0.007316    39.12  sec\n",
      " 42     0.000075      0.000046      0.005813      0.006404      0.005787    39.01  sec\n",
      " 43     0.000067      0.000054      0.006313      0.007104      0.006278    39.04  sec\n",
      " 44     0.000057      0.000039      0.005390      0.005854      0.005370    39.11  sec\n",
      " 45     0.000127      0.000117      0.009349      0.010352      0.009305    39.15  sec\n",
      " 46     0.000098      0.000197      0.012353      0.012747      0.012336    39.12  sec\n",
      " 47     0.000068      0.000043      0.005720      0.005871      0.005713    42.18  sec\n",
      " 48     0.000102      0.000096      0.008169      0.010878      0.008050    40.99  sec\n",
      " 49     0.000057      0.000039      0.005573      0.005889      0.005559    40.34  sec\n",
      " 50     0.000045      0.000038      0.005259      0.005382      0.005254    40.46  sec\n",
      " 51     0.000073      0.000051      0.006249      0.006555      0.006235    40.43  sec\n",
      " 52     0.000055      0.000051      0.006478      0.007789      0.006420    40.45  sec\n",
      " 53     0.000053      0.000034      0.005136      0.005302      0.005128    40.26  sec\n",
      " 54     0.000038      0.000037      0.005441      0.005903      0.005420    40.26  sec\n",
      " 55     0.000058      0.000056      0.006653      0.007913      0.006597    40.25  sec\n",
      " 56     0.000068      0.000034      0.005181      0.005944      0.005147    40.40  sec\n",
      " 57     0.000049      0.000046      0.006217      0.006373      0.006210    40.40  sec\n",
      " 58     0.000051      0.000098      0.009193      0.010298      0.009144    40.56  sec\n",
      " 59     0.000047      0.000043      0.005805      0.006749      0.005763    39.22  sec\n",
      "epoch   trn_loss      val_loss    val_rel_err  val_rel_err_o val_rel_err_h run_time\n",
      " 60     0.000058      0.000033      0.004947      0.005628      0.004917    39.22  sec\n",
      " 61     0.000050      0.000080      0.007996      0.008626      0.007968    39.14  sec\n",
      " 62     0.000095      0.000069      0.007575      0.008860      0.007518    39.11  sec\n",
      " 63     0.000075      0.000127      0.010521      0.011256      0.010488    39.00  sec\n",
      " 64     0.000068      0.000118      0.009598      0.011848      0.009498    39.07  sec\n",
      " 65     0.000083      0.000075      0.007455      0.008841      0.007394    39.11  sec\n",
      " 66     0.000071      0.000101      0.008443      0.011072      0.008327    39.35  sec\n",
      " 67     0.000086      0.000039      0.005407      0.005729      0.005392    39.72  sec\n",
      " 68     0.000058      0.000052      0.006348      0.006772      0.006330    39.15  sec\n",
      " 69     0.000053      0.000055      0.006589      0.006377      0.006599    39.19  sec\n",
      " 70     0.000090      0.000040      0.005421      0.006353      0.005380    39.16  sec\n",
      " 71     0.000045      0.000035      0.005178      0.005298      0.005172    39.17  sec\n",
      " 72     0.000044      0.000041      0.005704      0.006245      0.005680    39.08  sec\n",
      " 73     0.000051      0.000049      0.006252      0.006648      0.006235    39.04  sec\n",
      " 74     0.000068      0.000038      0.005360      0.005866      0.005337    39.17  sec\n",
      " 75     0.000047      0.000028      0.004703      0.004789      0.004699    40.38  sec\n",
      " 76     0.000044      0.000047      0.006437      0.006923      0.006416    41.21  sec\n",
      " 77     0.000047      0.000034      0.005168      0.005542      0.005152    39.32  sec\n",
      " 78     0.000092      0.000068      0.007431      0.007003      0.007450    39.48  sec\n",
      " 79     0.000064      0.000048      0.006031      0.006971      0.005990    39.81  sec\n",
      "epoch   trn_loss      val_loss    val_rel_err  val_rel_err_o val_rel_err_h run_time\n",
      " 80     0.000064      0.000048      0.006103      0.006870      0.006070    39.63  sec\n",
      " 81     0.000055      0.000042      0.005879      0.006223      0.005864    39.70  sec\n",
      " 82     0.000044      0.000041      0.005595      0.005862      0.005583    39.82  sec\n",
      " 83     0.000050      0.000077      0.008288      0.008343      0.008285    39.76  sec\n",
      " 84     0.000076      0.000194      0.013570      0.014764      0.013517    39.98  sec\n",
      " 85     0.000108      0.000051      0.006207      0.007772      0.006138    43.36  sec\n",
      " 86     0.000056      0.000042      0.005658      0.006317      0.005629    40.50  sec\n",
      " 87     0.000056      0.000055      0.006800      0.007987      0.006748    39.62  sec\n",
      " 88     0.000054      0.000171      0.012858      0.014346      0.012792    39.66  sec\n",
      " 89     0.000100      0.000059      0.006885      0.006780      0.006889    39.60  sec\n",
      " 90     0.000068      0.000065      0.007312      0.007572      0.007301    39.74  sec\n",
      " 91     0.000061      0.000034      0.005051      0.005548      0.005030    39.66  sec\n",
      " 92     0.000056      0.000043      0.005906      0.006066      0.005899    40.52  sec\n",
      " 93     0.000041      0.000058      0.006751      0.007469      0.006719    41.96  sec\n",
      " 94     0.000078      0.000098      0.009234      0.009705      0.009213    41.86  sec\n",
      " 95     0.000101      0.000066      0.007451      0.008044      0.007425    42.00  sec\n",
      " 96     0.000054      0.000085      0.008626      0.007988      0.008655    41.52  sec\n",
      " 97     0.000098      0.000095      0.008855      0.009369      0.008832    41.99  sec\n",
      " 98     0.000057      0.000118      0.010332      0.010062      0.010344    41.83  sec\n",
      " 99     0.000057      0.000046      0.005959      0.006417      0.005939    41.79  sec\n",
      "epoch   trn_loss      val_loss    val_rel_err  val_rel_err_o val_rel_err_h run_time\n",
      " 100    0.000061      0.000049      0.006451      0.006023      0.006470    42.24  sec\n",
      "\n",
      "Saving training results to './studies/logs/l-town-chebnet-pipe_length-minmax-self_loop-2.csv'...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training starting...\\n\")\n",
    "\n",
    "# Train for the predefined number of epochs\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    # Start a stopwatch timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train a single epoch, passing the optimizer and current epoch number\n",
    "    model.train_one_epoch(optimizer = optimizer)\n",
    "    \n",
    "    # Validate the model after the gradient update\n",
    "    model.validate()\n",
    "    \n",
    "    # Update the model results for the current epoch\n",
    "    model.update_results()\n",
    "    \n",
    "    # Print stats for the epoch and the execution time\n",
    "    model.print_stats(time.time() - start_time)\n",
    "    \n",
    "    # If this is the best model\n",
    "    if model.val_loss < model.best_val_loss:\n",
    "        # We save it\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # If model is not improving\n",
    "    if estop.step(torch.tensor(model.val_loss)):\n",
    "        print('Early stopping activated...')\n",
    "        break\n",
    "\n",
    "print(\"\\nSaving training results to '{}'...\\n\".format(log_path))\n",
    "model.results.to_csv(log_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
